{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.3.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.1.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.0.8)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "\n",
    "from data import DATA_SET_DIR\n",
    "from elmo.lm_generator import LMDataGenerator\n",
    "from elmo.model import ELMo\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000000/4000000 [00:03<00:00, 1104970.88it/s]\n",
      "  4%|▎         | 61941/1750000 [00:00<00:02, 619403.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分数据集\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750000/1750000 [00:02<00:00, 700794.78it/s]\n",
      "100%|██████████| 250000/250000 [00:00<00:00, 636351.00it/s]\n",
      "100%|██████████| 2000000/2000000 [00:02<00:00, 697327.92it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('./data/datasets/txt/advertiser_id.all.tokens', 'r') as f:\n",
    "    for i in tqdm(f.readlines()):\n",
    "        data.append(i[:-1])\n",
    "print('划分数据集')\n",
    "with open('./data/datasets/txt/advertiser_id.train.tokens', 'w') as f:\n",
    "    for i in tqdm(data[:1750000]):\n",
    "        f.write(i)\n",
    "        f.write('\\n')\n",
    "with open('./data/datasets/txt/advertiser_id.valid.tokens', 'w') as f:\n",
    "    for i in tqdm(data[1750000:2000000]):\n",
    "        f.write(i)\n",
    "        f.write('\\n')\n",
    "with open('./data/datasets/txt/advertiser_id.test.tokens', 'w') as f:\n",
    "    for i in tqdm(data[2000000:]):\n",
    "        f.write(i)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750000/1750000 [00:01<00:00, 1056098.59it/s]\n",
      "100%|██████████| 250000/250000 [00:00<00:00, 965795.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# 利用验证、训练数据制作词表\n",
    "data = []\n",
    "with open('./data/datasets/txt/advertiser_id.train.tokens', 'r') as f:\n",
    "    for i in tqdm(f.readlines()):\n",
    "        data.append(i[:-1])\n",
    "with open('./data/datasets/txt/advertiser_id.valid.tokens', 'r') as f:\n",
    "    for i in tqdm(f.readlines()):\n",
    "        data.append(i[:-1])\n",
    "\n",
    "words = []\n",
    "for i in data:\n",
    "    words += i.split(' ')\n",
    "words = set(words) - set(('<unk>',))\n",
    "vocab = {}\n",
    "vocab['<pad>'] = 0\n",
    "vocab['<bos>'] = 1\n",
    "vocab['<eos>'] = 2\n",
    "vocab['<unk>'] = 3\n",
    "i = 0\n",
    "for i, word in tqdm(enumerate(words)):\n",
    "    vocab[word] = i + 4\n",
    "with open('./data/datasets/txt/advertiser_id.vocab', 'w') as f:\n",
    "    for i in tqdm(vocab):\n",
    "        f.write('{} {}\\n'.format(i, vocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output sampled_softmax_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sampled_softmax_2.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n",
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output sampled_softmax_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sampled_softmax_3.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_indices (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_encoding (Embedding)      (None, None, 200)    10967400    word_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, None, 200)    0           token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "timestep_dropout_3 (TimestepDro (None, None, 200)    0           spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, 200)    0           timestep_dropout_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)       (None, None, 400)    963200      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, None, 200)    0           spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)        (None, None, 400)    963200      timestep_dropout_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_11 (Camouflage)      (None, None, 400)    0           cu_dnnlstm_11[0][0]              \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_9 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_9[0][0]               \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, None, 200)    80200       camouflage_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, 200)    80200       camouflage_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_1 (Add)                 (None, None, 200)    0           time_distributed_11[0][0]        \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "f_block_1 (Add)                 (None, None, 200)    0           time_distributed_9[0][0]         \n",
      "                                                                 timestep_dropout_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, None, 200)    0           b_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, None, 200)    0           f_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_12 (CuDNNLSTM)       (None, None, 400)    963200      spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_10 (CuDNNLSTM)       (None, None, 400)    963200      spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_12 (Camouflage)      (None, None, 400)    0           cu_dnnlstm_12[0][0]              \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_10 (Camouflage)      (None, None, 400)    0           cu_dnnlstm_10[0][0]              \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, None, 200)    80200       camouflage_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, None, 200)    80200       camouflage_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "b_block_2 (Add)                 (None, None, 200)    0           time_distributed_12[0][0]        \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "f_block_2 (Add)                 (None, None, 200)    0           time_distributed_10[0][0]        \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, None, 200)    0           b_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, None, 200)    0           f_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_ids (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reverse (Lambda)                (None, None, 200)    0           spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "previous_ids (InputLayer)       (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sampled_softmax_3 (SampledSoftm (None, None, 200)    11022237    spatial_dropout1d_13[0][0]       \n",
      "                                                                 next_ids[0][0]                   \n",
      "                                                                 reverse[0][0]                    \n",
      "                                                                 previous_ids[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,195,837\n",
      "Trainable params: 15,195,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   71/54688 [..............................] - ETA: 22:24:58 - loss: 120.5444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-9:\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-15:\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 406, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'multi_processing': True,\n",
    "    'n_threads': os.cpu_count(),\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'txt/advertiser_id.train.tokens',\n",
    "    'valid_dataset': 'txt/advertiser_id.valid.tokens',\n",
    "    'test_dataset': 'txt/advertiser_id.test.tokens',\n",
    "    'vocab': 'txt/advertiser_id.vocab',\n",
    "    'vocab_size': 54837,\n",
    "    'num_sampled': 1000,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 100,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 10,\n",
    "    'patience': 2,\n",
    "    'batch_size': 16,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': True,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_highway_layers': 2,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "                    [4, 128],\n",
    "                    [5, 256],\n",
    "                    [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 400,\n",
    "    'hidden_units_size': 200,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "}\n",
    "\n",
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# Compile ELMo\n",
    "print('compile')\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=True)\n",
    "\n",
    "# Train ELMo\n",
    "print('train')\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator)\n",
    "\n",
    "# Persist ELMo Bidirectional Language Model in disk\n",
    "print('save')\n",
    "elmo_model.save(sampled_softmax=False)\n",
    "\n",
    "# Evaluate Bidirectional Language Model\n",
    "print('evaluate')\n",
    "elmo_model.evaluate(test_generator)\n",
    "\n",
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "print('??')\n",
    "elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)\n",
    "\n",
    "# Load ELMo encoder\n",
    "print('load')\n",
    "elmo_model.load_elmo_encoder()\n",
    "\n",
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')\n",
    "\n",
    "# BUILD & TRAIN NEW KERAS MODEL FOR DOWNSTREAM TASK (E.G., TEXT CLASSIFICATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output sampled_softmax_9 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sampled_softmax_9.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n",
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output sampled_softmax_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sampled_softmax_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_indices (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_encoding (Embedding)      (None, None, 200)    252000      word_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, None, 200)    0           token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "timestep_dropout_1 (TimestepDro (None, None, 200)    0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 200)    0           timestep_dropout_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)        (None, None, 400)    963200      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 200)    0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, None, 400)    963200      timestep_dropout_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_3 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_3[0][0]               \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_1 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_1[0][0]               \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 200)    80200       camouflage_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 200)    80200       camouflage_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_1 (Add)                 (None, None, 200)    0           time_distributed_3[0][0]         \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "f_block_1 (Add)                 (None, None, 200)    0           time_distributed_1[0][0]         \n",
      "                                                                 timestep_dropout_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, None, 200)    0           b_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, None, 200)    0           f_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_4 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_4[0][0]               \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_2 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_2[0][0]               \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, None, 200)    80200       camouflage_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 200)    80200       camouflage_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_2 (Add)                 (None, None, 200)    0           time_distributed_4[0][0]         \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "f_block_2 (Add)                 (None, None, 200)    0           time_distributed_2[0][0]         \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, None, 200)    0           b_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, None, 200)    0           f_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_ids (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reverse (Lambda)                (None, None, 200)    0           spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "previous_ids (InputLayer)       (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sampled_softmax_1 (SampledSoftm (None, None, 200)    253260      spatial_dropout1d_3[0][0]        \n",
      "                                                                 next_ids[0][0]                   \n",
      "                                                                 reverse[0][0]                    \n",
      "                                                                 previous_ids[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,426,860\n",
      "Trainable params: 4,426,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ELMo.__del__ of <elmo.model.ELMo object at 0x7f31ac238588>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tione/notebook/ELMo-keras/elmo/model.py\", line 29, in __del__\n",
      "    K.clear_session()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 414, in clear_session\n",
      "    tf_keras_backend.clear_session()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 232, in clear_session\n",
      "    ops.reset_default_graph()\n",
      "  File \"/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 5852, in reset_default_graph\n",
      "    raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n",
      "AssertionError: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.\n",
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 148.2817 - val_loss: 1.3953\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.39525, saving model to /home/tione/notebook/ELMo-keras/data/models/elmo_best_weights.hdf5\n",
      "Epoch 2/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 33.2155 - val_loss: 68.0619\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.39525\n",
      "Epoch 3/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 30.7912 - val_loss: 9.6564\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.39525\n",
      "Epoch 4/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 19.1150 - val_loss: 10.7415\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.39525\n",
      "Epoch 5/10\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 15.4239 - val_loss: 12.2715\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.39525\n",
      "Epoch 6/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 12.3678 - val_loss: 7.2310\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.39525\n",
      "Epoch 7/10\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 10.6665 - val_loss: 3.8683\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.39525\n",
      "Epoch 8/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 9.3093 - val_loss: 4.2843\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.39525\n",
      "Epoch 9/10\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 8.0383 - val_loss: 3.1645\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.39525\n",
      "Epoch 10/10\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 6.4179 - val_loss: 4.4778\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.39525\n",
      "Training took 72.30446577072144 sec\n",
      "save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output sampled_softmax_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to sampled_softmax_2.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo Language Model saved successfully\n",
      "evaluate\n",
      "Forward Langauge Model Perplexity: 61232.054662230556\n",
      "Backward Langauge Model Perplexity: 16723.494255278456\n",
      "??\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_indices (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_encoding (Embedding)      (None, None, 200)    252000      word_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, None, 200)    0           token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "timestep_dropout_2 (TimestepDro (None, None, 200)    0           spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 200)    0           timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)        (None, None, 400)    963200      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 200)    0           spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)        (None, None, 400)    963200      timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_7 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_7[0][0]               \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_5 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_5[0][0]               \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 200)    80200       camouflage_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, None, 200)    80200       camouflage_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_1 (Add)                 (None, None, 200)    0           time_distributed_7[0][0]         \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "f_block_1 (Add)                 (None, None, 200)    0           time_distributed_5[0][0]         \n",
      "                                                                 timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, None, 200)    0           b_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, None, 200)    0           f_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_8 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_8[0][0]               \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_6 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_6[0][0]               \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 200)    80200       camouflage_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 200)    80200       camouflage_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_2 (Add)                 (None, None, 200)    0           time_distributed_8[0][0]         \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, 200)    0           b_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "f_block_2 (Add)                 (None, None, 200)    0           time_distributed_6[0][0]         \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, None, 200)    0           b_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "elmo_embeddings_level_0 (Concat (None, None, 400)    0           token_encoding[0][0]             \n",
      "                                                                 token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "elmo_embeddings_level_1 (Concat (None, None, 400)    0           f_block_1[0][0]                  \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elmo_embeddings_level_2 (Concat (None, None, 400)    0           f_block_2[0][0]                  \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camo_elmo_embeddings_level_1 (C (None, None, 400)    0           elmo_embeddings_level_0[0][0]    \n",
      "                                                                 token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "camo_elmo_embeddings_level_2 (C (None, None, 400)    0           elmo_embeddings_level_1[0][0]    \n",
      "                                                                 token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "camo_elmo_embeddings_level_3 (C (None, None, 400)    0           elmo_embeddings_level_2[0][0]    \n",
      "                                                                 token_encoding[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,425,600\n",
      "Trainable params: 4,425,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "ELMo Encoder saved successfully\n",
      "load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'multi_processing': False,\n",
    "    'n_threads': 4,\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'txt/advertiser_id.demo.tokens',\n",
    "    'valid_dataset': 'txt/advertiser_id.demo.tokens',\n",
    "    'test_dataset': 'txt/advertiser_id.demo.tokens',\n",
    "    'vocab': 'txt/advertiser_id.demo.vocab',\n",
    "    'vocab_size': len(vocab),\n",
    "    'num_sampled': 1000,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 100,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 10,\n",
    "    'patience': 2,\n",
    "    'batch_size': 1,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': True,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_highway_layers': 2,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "                    [4, 128],\n",
    "                    [5, 256],\n",
    "                    [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 400,\n",
    "    'hidden_units_size': 200,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "}\n",
    "\n",
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# Compile ELMo\n",
    "print('compile')\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=True)\n",
    "\n",
    "# Train ELMo\n",
    "print('train')\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator)\n",
    "\n",
    "# Persist ELMo Bidirectional Language Model in disk\n",
    "print('save')\n",
    "elmo_model.save(sampled_softmax=False)\n",
    "\n",
    "# Evaluate Bidirectional Language Model\n",
    "print('evaluate')\n",
    "elmo_model.evaluate(test_generator)\n",
    "\n",
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "print('??')\n",
    "elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)\n",
    "\n",
    "# Load ELMo encoder\n",
    "print('load')\n",
    "elmo_model.load_elmo_encoder()\n",
    "\n",
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')\n",
    "\n",
    "# BUILD & TRAIN NEW KERAS MODEL FOR DOWNSTREAM TASK (E.G., TEXT CLASSIFICATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5028853 ,  3.0094678 ,  5.5926957 , ...,  1.5612016 ,\n",
       "        -0.11298636,  0.47743785],\n",
       "       [-3.2986498 ,  3.639497  ,  6.418512  , ...,  2.088767  ,\n",
       "         0.02384794,  0.9044669 ],\n",
       "       [-3.80541   ,  4.118277  ,  7.1731715 , ...,  2.4383476 ,\n",
       "         0.1849048 ,  1.23097   ],\n",
       "       ...,\n",
       "       [-3.160855  ,  3.628611  ,  6.444164  , ...,  2.0874894 ,\n",
       "        -0.00931854,  0.88850296],\n",
       "       [-3.5049515 ,  3.9199624 ,  6.8536725 , ...,  2.2042162 ,\n",
       "         0.11237423,  1.0343972 ],\n",
       "       [-4.549523  ,  4.703183  ,  7.9132166 , ...,  2.8450491 ,\n",
       "         0.28287318,  1.5878644 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
