{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.3.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.5.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.3.1) (2.10.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.backend as K\n",
    "\n",
    "from data import DATA_SET_DIR\n",
    "from elmo.lm_generator import LMDataGenerator\n",
    "from elmo.model import ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/datasets/txt/advertiser_id.vocab') as f:\n",
    "    vocab = [line[:-2] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_indices (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_encoding (Embedding)      (None, None, 200)    11208800    word_indices[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, None, 200)    0           token_encoding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "timestep_dropout_2 (TimestepDro (None, None, 200)    0           spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 200)    0           timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)        (None, None, 400)    963200      lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, 200)    0           spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)        (None, None, 400)    963200      timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_7 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_7[0][0]               \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_5 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_5[0][0]               \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 200)    80200       camouflage_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, None, 200)    80200       camouflage_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_1 (Add)                 (None, None, 200)    0           time_distributed_7[0][0]         \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "f_block_1 (Add)                 (None, None, 200)    0           time_distributed_5[0][0]         \n",
      "                                                                 timestep_dropout_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, None, 200)    0           b_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, None, 200)    0           f_block_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)        (None, None, 400)    963200      spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_8 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_8[0][0]               \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "camouflage_6 (Camouflage)       (None, None, 400)    0           cu_dnnlstm_6[0][0]               \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 200)    80200       camouflage_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 200)    80200       camouflage_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "b_block_2 (Add)                 (None, None, 200)    0           time_distributed_8[0][0]         \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "f_block_2 (Add)                 (None, None, 200)    0           time_distributed_6[0][0]         \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, None, 200)    0           b_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, None, 200)    0           f_block_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "next_ids (InputLayer)           (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reverse (Lambda)                (None, None, 200)    0           spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "previous_ids (InputLayer)       (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sampled_softmax_2 (SampledSoftm (None, None, 200)    11264844    spatial_dropout1d_8[0][0]        \n",
      "                                                                 next_ids[0][0]                   \n",
      "                                                                 reverse[0][0]                    \n",
      "                                                                 previous_ids[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 15,438,444\n",
      "Trainable params: 15,438,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/3\n",
      " 12018/156250 [=>............................] - ETA: 8:11:10 - loss: 1.6729"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'multi_processing': True,\n",
    "    'n_threads': -1,\n",
    "    'cuDNN': True if len(K.tensorflow_backend._get_available_gpus()) else False,\n",
    "    'train_dataset': 'txt/advertiser_id.train.tokens',\n",
    "    'valid_dataset': 'txt/advertiser_id.dev.tokens',\n",
    "    'test_dataset': 'txt/advertiser_id.test.tokens',\n",
    "    'vocab': 'txt/ad_id.vocab',\n",
    "    'vocab_size': 56044,\n",
    "    'num_sampled': 500,\n",
    "    'charset_size': 262,\n",
    "    'sentence_maxlen': 100,\n",
    "    'token_maxlen': 50,\n",
    "    'token_encoding': 'word',\n",
    "    'epochs': 3,\n",
    "    'patience': 2,\n",
    "    'batch_size': 4,\n",
    "    'clip_value': 1,\n",
    "    'cell_clip': 5,\n",
    "    'proj_clip': 5,\n",
    "    'lr': 0.2,\n",
    "    'shuffle': True,\n",
    "    'n_lstm_layers': 2,\n",
    "    'n_highway_layers': 2,\n",
    "    'cnn_filters': [[1, 32],\n",
    "                    [2, 32],\n",
    "                    [3, 64],\n",
    "#                     [4, 128],\n",
    "                    [5, 256],\n",
    "#                     [6, 512],\n",
    "                    [7, 512]\n",
    "                    ],\n",
    "    'lstm_units_size': 400,\n",
    "    'hidden_units_size': 200,\n",
    "    'char_embedding_size': 16,\n",
    "    'dropout_rate': 0.1,\n",
    "    'word_dropout_rate': 0.05,\n",
    "    'weight_tying': True,\n",
    "}\n",
    "\n",
    "# Set-up Generators\n",
    "train_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['train_dataset']),\n",
    "                                  os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                  sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                  token_maxlen=parameters['token_maxlen'],\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  shuffle=parameters['shuffle'],\n",
    "                                  token_encoding=parameters['token_encoding'])\n",
    "\n",
    "val_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['valid_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "test_generator = LMDataGenerator(os.path.join(DATA_SET_DIR, parameters['test_dataset']),\n",
    "                                os.path.join(DATA_SET_DIR, parameters['vocab']),\n",
    "                                sentence_maxlen=parameters['sentence_maxlen'],\n",
    "                                token_maxlen=parameters['token_maxlen'],\n",
    "                                batch_size=parameters['batch_size'],\n",
    "                                shuffle=parameters['shuffle'],\n",
    "                                token_encoding=parameters['token_encoding'])\n",
    "\n",
    "# Compile ELMo\n",
    "elmo_model = ELMo(parameters)\n",
    "elmo_model.compile_elmo(print_summary=True)\n",
    "\n",
    "# Train ELMo\n",
    "elmo_model.train(train_data=train_generator, valid_data=val_generator)\n",
    "\n",
    "# Persist ELMo Bidirectional Language Model in disk\n",
    "elmo_model.save(sampled_softmax=False)\n",
    "\n",
    "# Evaluate Bidirectional Language Model\n",
    "elmo_model.evaluate(test_generator)\n",
    "\n",
    "# Build ELMo meta-model to deploy for production and persist in disk\n",
    "elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)\n",
    "\n",
    "# Load ELMo encoder\n",
    "elmo_model.load_elmo_encoder()\n",
    "\n",
    "# Get ELMo embeddings to feed as inputs for downstream tasks\n",
    "elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')\n",
    "\n",
    "# BUILD & TRAIN NEW KERAS MODEL FOR DOWNSTREAM TASK (E.G., TEXT CLASSIFICATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.963724 ,  15.389417 , -14.823316 , ...,  -2.264004 ,\n",
       "          2.0712223,   7.9908032],\n",
       "       [ -0.765509 ,   3.2414885,  -1.96873  , ...,  -0.4388038,\n",
       "          0.3472507,   1.1737093],\n",
       "       [ -5.7815394,  15.513747 , -14.713231 , ...,  -2.2619948,\n",
       "          2.0751145,   7.97468  ],\n",
       "       ...,\n",
       "       [ -5.811864 ,  15.317462 , -14.770313 , ...,  -2.2618427,\n",
       "          2.0867224,   7.939979 ],\n",
       "       [ -3.583551 ,  11.9998865,  -9.664206 , ...,  -2.7930157,\n",
       "          2.3017042,   2.5163767],\n",
       "       [ -5.783086 ,  14.875971 , -13.583462 , ...,  -2.2849314,\n",
       "          2.0599265,   7.4962587]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
